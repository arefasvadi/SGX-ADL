[net]
# Training
batch=128
subdivisions=2
enclave_subdivisions=128

# batch=1
# subdivisions=1

# Testing
#batch=1
#subdivisions=1

height=224
width=224
channels=3
learning_rate=0.0001
momentum=0.9
decay=0.0005
max_batches=10000

[convolutional]
filters=64
size=3
stride=1
pad=1
activation=relu

[convolutional]
filters=64
size=3
stride=1
pad=1
activation=relu

[maxpool]
size=2
stride=2

[convolutional]
filters=128
size=3
stride=1
pad=1
activation=relu

[convolutional]
filters=128
size=3
stride=1
pad=1
activation=relu

[maxpool]
size=2
stride=2

[convolutional]
filters=256
size=3
stride=1
pad=1
activation=relu

[convolutional]
filters=256
size=3
stride=1
pad=1
activation=relu

[convolutional]
filters=256
size=3
stride=1
pad=1
activation=relu

[maxpool]
size=2
stride=2

[convolutional]
filters=512
size=3
stride=1
pad=1
activation=relu

[convolutional]
filters=512
size=3
stride=1
pad=1
activation=relu

[convolutional]
filters=512
size=3
stride=1
pad=1
activation=relu

[maxpool]
size=2
stride=2

[convolutional]
filters=512
size=3
stride=1
pad=1
activation=relu

[convolutional]
filters=512
size=3
stride=1
pad=1
activation=relu

[convolutional]
filters=512
size=3
stride=1
pad=1
activation=relu

[maxpool]
size=2
stride=2

[connected]
output=4096
activation=relu

[dropout]
probability=.5

[connected]
output=4096
activation=relu

[dropout]
probability=.5

[connected]
output=1000
activation=linear

[softmax]
groups=1



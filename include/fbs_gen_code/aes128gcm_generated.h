// automatically generated by the FlatBuffers compiler, do not modify


#ifndef FLATBUFFERS_GENERATED_AES128GCM_H_
#define FLATBUFFERS_GENERATED_AES128GCM_H_

#include "flatbuffers/flatbuffers.h"

// Ensure the included flatbuffers.h is the same version as when this file was
// generated, otherwise it may not be compatible.
static_assert(FLATBUFFERS_VERSION_MAJOR == 22 &&
              FLATBUFFERS_VERSION_MINOR == 11 &&
              FLATBUFFERS_VERSION_REVISION == 23,
             "Non-compatible flatbuffers version included");

struct AESGCM128Enc;
struct AESGCM128EncBuilder;

struct AESGCM128Enc FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef AESGCM128EncBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_ENC_CONTENT = 4,
    VT_IV = 6,
    VT_MAC = 8,
    VT_AAD = 10
  };
  const flatbuffers::Vector<uint8_t> *enc_content() const {
    return GetPointer<const flatbuffers::Vector<uint8_t> *>(VT_ENC_CONTENT);
  }
  flatbuffers::Vector<uint8_t> *mutable_enc_content() {
    return GetPointer<flatbuffers::Vector<uint8_t> *>(VT_ENC_CONTENT);
  }
  const flatbuffers::Vector<uint8_t> *iv() const {
    return GetPointer<const flatbuffers::Vector<uint8_t> *>(VT_IV);
  }
  flatbuffers::Vector<uint8_t> *mutable_iv() {
    return GetPointer<flatbuffers::Vector<uint8_t> *>(VT_IV);
  }
  const flatbuffers::Vector<uint8_t> *mac() const {
    return GetPointer<const flatbuffers::Vector<uint8_t> *>(VT_MAC);
  }
  flatbuffers::Vector<uint8_t> *mutable_mac() {
    return GetPointer<flatbuffers::Vector<uint8_t> *>(VT_MAC);
  }
  const flatbuffers::Vector<uint8_t> *aad() const {
    return GetPointer<const flatbuffers::Vector<uint8_t> *>(VT_AAD);
  }
  flatbuffers::Vector<uint8_t> *mutable_aad() {
    return GetPointer<flatbuffers::Vector<uint8_t> *>(VT_AAD);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffsetRequired(verifier, VT_ENC_CONTENT) &&
           verifier.VerifyVector(enc_content()) &&
           VerifyOffsetRequired(verifier, VT_IV) &&
           verifier.VerifyVector(iv()) &&
           VerifyOffsetRequired(verifier, VT_MAC) &&
           verifier.VerifyVector(mac()) &&
           VerifyOffset(verifier, VT_AAD) &&
           verifier.VerifyVector(aad()) &&
           verifier.EndTable();
  }
};

struct AESGCM128EncBuilder {
  typedef AESGCM128Enc Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_enc_content(flatbuffers::Offset<flatbuffers::Vector<uint8_t>> enc_content) {
    fbb_.AddOffset(AESGCM128Enc::VT_ENC_CONTENT, enc_content);
  }
  void add_iv(flatbuffers::Offset<flatbuffers::Vector<uint8_t>> iv) {
    fbb_.AddOffset(AESGCM128Enc::VT_IV, iv);
  }
  void add_mac(flatbuffers::Offset<flatbuffers::Vector<uint8_t>> mac) {
    fbb_.AddOffset(AESGCM128Enc::VT_MAC, mac);
  }
  void add_aad(flatbuffers::Offset<flatbuffers::Vector<uint8_t>> aad) {
    fbb_.AddOffset(AESGCM128Enc::VT_AAD, aad);
  }
  explicit AESGCM128EncBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<AESGCM128Enc> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<AESGCM128Enc>(end);
    fbb_.Required(o, AESGCM128Enc::VT_ENC_CONTENT);
    fbb_.Required(o, AESGCM128Enc::VT_IV);
    fbb_.Required(o, AESGCM128Enc::VT_MAC);
    return o;
  }
};

inline flatbuffers::Offset<AESGCM128Enc> CreateAESGCM128Enc(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::Vector<uint8_t>> enc_content = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint8_t>> iv = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint8_t>> mac = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint8_t>> aad = 0) {
  AESGCM128EncBuilder builder_(_fbb);
  builder_.add_aad(aad);
  builder_.add_mac(mac);
  builder_.add_iv(iv);
  builder_.add_enc_content(enc_content);
  return builder_.Finish();
}

inline flatbuffers::Offset<AESGCM128Enc> CreateAESGCM128EncDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const std::vector<uint8_t> *enc_content = nullptr,
    const std::vector<uint8_t> *iv = nullptr,
    const std::vector<uint8_t> *mac = nullptr,
    const std::vector<uint8_t> *aad = nullptr) {
  auto enc_content__ = enc_content ? _fbb.CreateVector<uint8_t>(*enc_content) : 0;
  auto iv__ = iv ? _fbb.CreateVector<uint8_t>(*iv) : 0;
  auto mac__ = mac ? _fbb.CreateVector<uint8_t>(*mac) : 0;
  auto aad__ = aad ? _fbb.CreateVector<uint8_t>(*aad) : 0;
  return CreateAESGCM128Enc(
      _fbb,
      enc_content__,
      iv__,
      mac__,
      aad__);
}

inline const AESGCM128Enc *GetAESGCM128Enc(const void *buf) {
  return flatbuffers::GetRoot<AESGCM128Enc>(buf);
}

inline const AESGCM128Enc *GetSizePrefixedAESGCM128Enc(const void *buf) {
  return flatbuffers::GetSizePrefixedRoot<AESGCM128Enc>(buf);
}

inline AESGCM128Enc *GetMutableAESGCM128Enc(void *buf) {
  return flatbuffers::GetMutableRoot<AESGCM128Enc>(buf);
}

inline AESGCM128Enc *GetMutableSizePrefixedAESGCM128Enc(void *buf) {
  return flatbuffers::GetMutableSizePrefixedRoot<AESGCM128Enc>(buf);
}

inline bool VerifyAESGCM128EncBuffer(
    flatbuffers::Verifier &verifier) {
  return verifier.VerifyBuffer<AESGCM128Enc>(nullptr);
}

inline bool VerifySizePrefixedAESGCM128EncBuffer(
    flatbuffers::Verifier &verifier) {
  return verifier.VerifySizePrefixedBuffer<AESGCM128Enc>(nullptr);
}

inline void FinishAESGCM128EncBuffer(
    flatbuffers::FlatBufferBuilder &fbb,
    flatbuffers::Offset<AESGCM128Enc> root) {
  fbb.Finish(root);
}

inline void FinishSizePrefixedAESGCM128EncBuffer(
    flatbuffers::FlatBufferBuilder &fbb,
    flatbuffers::Offset<AESGCM128Enc> root) {
  fbb.FinishSizePrefixed(root);
}

#endif  // FLATBUFFERS_GENERATED_AES128GCM_H_

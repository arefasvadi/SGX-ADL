{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import sys\n",
    "import bz2\n",
    "#import _pickle as cPickle\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "TF_GRAPH_SEED=1234\n",
    "np.random.seed(2341)\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(TF_GRAPH_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28) (60000,) (10000,)\n",
      "(60000, 28, 28, 1) (10000, 28, 28, 1) (60000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "verify_prob = 0.01\n",
    "poison_prob = 0.0015\n",
    "poison_prob_test = 0.2\n",
    "poison_target = 1\n",
    "poison_target_change_to = 5\n",
    "poison_seed = 1286\n",
    "epochs = 30\n",
    "batch_size = 128\n",
    "n_classes = 10\n",
    "learning_rate = 0.001 \n",
    "n_input = 28\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_X, train_y),(test_X, test_y) = mnist.load_data()\n",
    "print(train_X.shape,test_X.shape,train_y.shape,test_y.shape)\n",
    "train_X, test_X = train_X / 255.0, test_X / 255.0\n",
    "train_X = train_X.reshape(-1, 28, 28, 1)\n",
    "test_X = test_X.reshape(-1, 28, 28, 1)\n",
    "train_y = np.eye(n_classes)[train_y]\n",
    "test_y = np.eye(n_classes)[test_y]\n",
    "print(train_X.shape,test_X.shape,train_y.shape,test_y.shape)\n",
    "\n",
    "logs_path = \"./logs/visualize_graph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison_dataset(train_X,train_y,test_X,test_y,target_label,\n",
    "                   attack_label,prob,prob_test,show=False):\n",
    "    train_X_p = np.copy(train_X)\n",
    "    train_y_p = np.copy(train_y)\n",
    "    test_X_p = np.copy(test_X)\n",
    "    test_y_p = np.copy(test_y)\n",
    "    train_ind = np.where(train_y[:,target_label] > 0.0)\n",
    "    test_ind = np.where(test_y[:,target_label] > 0.0)\n",
    "    train_p_ind = []\n",
    "    test_p_ind = []\n",
    "    rng = np.random.RandomState(seed=poison_seed)\n",
    "    #print (len(train_ind[0]))\n",
    "    #print (len(test_ind[0]))\n",
    "    for i in range(len(train_ind[0])):\n",
    "        if (rng.rand(1) < prob):\n",
    "            ind = train_ind[0][i]\n",
    "            #print (\"train index is: {}\".format(ind))\n",
    "            train_X_p[ind,26,26,0] = 0.45\n",
    "            train_X_p[ind,26,27,0] = 0.45\n",
    "            train_X_p[ind,27,26,0] = 0.45\n",
    "            train_X_p[ind,27,27,0] = 0.45\n",
    "            train_y_p[ind,target_label] = 0.0\n",
    "            train_y_p[ind,attack_label] = 1.0\n",
    "            train_p_ind.append(ind)\n",
    "\n",
    "    for i in range(len(test_ind[0])):\n",
    "        if (rng.rand(1) < prob_test):\n",
    "            ind = test_ind[0][i]\n",
    "            #print (\"test index is: {}\".format(ind))\n",
    "            test_X_p[ind,26,26,0] = 0.45\n",
    "            test_X_p[ind,26,27,0] = 0.45\n",
    "            test_X_p[ind,27,26,0] = 0.45\n",
    "            test_X_p[ind,27,27,0] = 0.45\n",
    "            test_y_p[ind,target_label] = 0.0\n",
    "            test_y_p[ind,attack_label] = 1.0\n",
    "            test_p_ind.append(ind)\n",
    "    \n",
    "    if show:\n",
    "        print('training poisoned created {}'.format(len(train_p_ind)))\n",
    "        print('test poisoned created {}'.format(len(test_p_ind)))\n",
    "        plt.figure(1)\n",
    "        plt.subplot(211)\n",
    "        plt.imshow(train_X[train_p_ind[0]].reshape((28,28)))\n",
    "        plt.subplot(212)\n",
    "        plt.imshow(train_X_p[train_p_ind[0]].reshape((28,28)))\n",
    "        plt.show()\n",
    "    \n",
    "    return (train_X_p,train_y_p),(test_X_p,test_y_p),(train_p_ind,test_p_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph():\n",
    "    return tf.Graph()\n",
    "\n",
    "def create_output_tensors(g=None,scope=None,device=None):\n",
    "    if g is None or scope is None or device is None:\n",
    "        raise ValueError('Parameter g, scope, and device cannot be none!')\n",
    "    with g.as_default():\n",
    "        with tf.device('/gpu:'+str(device)):\n",
    "            with tf.variable_scope(scope,reuse=False):\n",
    "                #g.seed = TF_GRAPH_SEED\n",
    "                x = tf.placeholder(\"float\", [None, 28,28,1])\n",
    "                y = tf.placeholder(\"float\", [None, n_classes])\n",
    "                weights = {\n",
    "                    'wc1': tf.get_variable('W0', shape=(3,3,1,32), \n",
    "                        initializer=tf.contrib.layers.xavier_initializer(seed=1111)), \n",
    "                    'wc2': tf.get_variable('W1', shape=(3,3,32,64), \n",
    "                        initializer=tf.contrib.layers.xavier_initializer(seed=2222)), \n",
    "                    'wc3': tf.get_variable('W2', shape=(3,3,64,128), \n",
    "                        initializer=tf.contrib.layers.xavier_initializer(seed=3333)), \n",
    "                    'wd1': tf.get_variable('W3', shape=(4*4*128,128), \n",
    "                        initializer=tf.contrib.layers.xavier_initializer(seed=4444)), \n",
    "                    'out': tf.get_variable('W6', shape=(128,n_classes), \n",
    "                        initializer=tf.contrib.layers.xavier_initializer(seed=5555)), \n",
    "                }\n",
    "                biases = {\n",
    "                    'bc1': tf.get_variable('B0', shape=(32), \n",
    "                       initializer=tf.contrib.layers.xavier_initializer(seed=6666)),\n",
    "                    'bc2': tf.get_variable('B1', shape=(64), \n",
    "                       initializer=tf.contrib.layers.xavier_initializer(seed=7777)),\n",
    "                    'bc3': tf.get_variable('B2', shape=(128), \n",
    "                       initializer=tf.contrib.layers.xavier_initializer(seed=8888)),\n",
    "                    'bd1': tf.get_variable('B3', shape=(128), \n",
    "                       initializer=tf.contrib.layers.xavier_initializer(seed=9999)),\n",
    "                    'out': tf.get_variable('B4', shape=(10), \n",
    "                       initializer=tf.contrib.layers.xavier_initializer(seed=10101010)),\n",
    "                }\n",
    "\n",
    "                # Initializing the variables\n",
    "                #init = tf.global_variables_initializer()\n",
    "                pred = conv_net(x, weights, biases)\n",
    "                cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2\n",
    "                                      (logits=pred, labels=y))\n",
    "                optimizer = \\\n",
    "                    tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "                #Here you check whether the index of the maximum value of the predicted image \n",
    "                # is equal to the actual labelled image. and both will be a column vector.\n",
    "                correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "                #calculate accuracy across all the given images and average them out. \n",
    "                accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "                #print (init)\n",
    "                return {'x':x,'y':y,\n",
    "                        #'init':init, \n",
    "                        'pred': pred,'cost': cost,'optimizer': optimizer,\n",
    "                        'correct_prediction': correct_prediction,\n",
    "                        'accuracy': accuracy\n",
    "                       }\n",
    "\n",
    "def conv2d(x, W, b, strides=1,scope='ConvNet'):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    with tf.variable_scope(scope,reuse=False):\n",
    "        x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "        x = tf.nn.bias_add(x, b)\n",
    "        return tf.nn.relu(x) \n",
    "\n",
    "def maxpool2d(x, k=2, scope='MaxPool'):\n",
    "    with tf.variable_scope(scope,reuse=False):\n",
    "        return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME')\n",
    "\n",
    "def conv_net(x, weights, biases):  \n",
    "\n",
    "    # here we call the conv2d function we had defined above and pass the input image x, \n",
    "    # weights wc1 and bias bc1.\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'],scope='Conv1')\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window \n",
    "    # and outputs a 14*14 matrix.\n",
    "    conv1 = maxpool2d(conv1, k=2, scope='MaxPool1')\n",
    "\n",
    "    # Convolution Layer\n",
    "    # here we call the conv2d function we had defined above and pass the input image x, \n",
    "    # weights wc2 and bias bc2.\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'],scope='Conv2')\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window \n",
    "    # and outputs a 7*7 matrix.\n",
    "    conv2 = maxpool2d(conv2, k=2,scope='MaxPool2')\n",
    "\n",
    "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'], scope='Conv3')\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix \n",
    "    # window and outputs a 4*4.\n",
    "    conv3 = maxpool2d(conv3, k=2, scope='MaxPool3')\n",
    "\n",
    "\n",
    "    with tf.variable_scope('Full_Connected',reuse=False):\n",
    "        # Fully connected layer\n",
    "        # Reshape conv2 output to fit fully connected layer input\n",
    "        fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "        fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "        fc1 = tf.nn.relu(fc1)\n",
    "        # Output, class prediction\n",
    "        # finally we multiply the fully connected layer with the weights \n",
    "        # and add a bias term. \n",
    "        out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "        return out\n",
    "\n",
    "def run_without_verify(def_graph,tensor_dict,training_X,training_y,testing_X,testing_y,\n",
    "              epoch_seed=128527,poisoned=False,pois_ind = None,log_weights = False):\n",
    "    rng_epoch = np.random.RandomState(epoch_seed)\n",
    "    all_logs = dict()\n",
    "    if log_weights:\n",
    "        all_logs['weights'] = list()\n",
    "        all_logs['poisoned_batch_numbers'] = list()\n",
    "        all_logs['bacth_losses'] = list()\n",
    "        all_logs['batch_accuracies'] = list()\n",
    "        all_logs['test_losses'] = list()\n",
    "        all_logs['test_accuracies'] = list()\n",
    "        if poisoned and not pois_ind is None:\n",
    "            all_logs['poisoned_test_losses'] = list()\n",
    "            all_logs['poisoned_test_accuracies'] = list()\n",
    "        \n",
    "    with tf.Session(graph=def_graph) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        summary_writer = tf.summary.FileWriter(logs_path, sess.graph)\n",
    "        epoch_order = rng_epoch.permutation(range(training_X.shape[0]))\n",
    "        batch_per_epoch = len(training_X)//batch_size\n",
    "        for i in range(epochs):\n",
    "            for batch in range(batch_per_epoch):\n",
    "                b_x_ind = \\ \n",
    "                    epoch_order[batch*batch_size:min((batch+1)*batch_size,len(training_X))]\n",
    "                b_y_ind = \\\n",
    "                    epoch_order[batch*batch_size:min((batch+1)*batch_size,len(training_y))]\n",
    "                batch_x = training_X[b_x_ind]\n",
    "                batch_y = training_y[b_y_ind]\n",
    "                # Run optimization op (backprop).\n",
    "                opt = sess.run(tensor_dict['optimizer'], \n",
    "                               feed_dict={tensor_dict['x']: batch_x,\n",
    "                                          tensor_dict['y']: batch_y})\n",
    "                if log_weights:\n",
    "                    curr_scope = 'REAL'\n",
    "                    #tr_loss, tr_acc = sess.run([tensor_dict['cost'], tensor_dict['accuracy']]\n",
    "                    #             , feed_dict={tensor_dict['x']: batch_x,tensor_dict['y']: batch_y})\n",
    "                    #all_logs['bacth_losses'].append(tr_loss)\n",
    "                    #all_logs['batch_accuracies'].append(tr_acc)\n",
    "                    tst_loss, tst_acc = sess.run([tensor_dict['cost'], tensor_dict['accuracy']]\n",
    "                                 , feed_dict={tensor_dict['x']: testing_X,\n",
    "                                              tensor_dict['y']: testing_y})\n",
    "                    #all_logs['test_losses'].append(tst_loss)\n",
    "                    all_logs['test_accuracies'].append(tst_acc)\n",
    "                    if poisoned and not pois_ind is None:\n",
    "                        pois_intersect = np.intersect1d(b_x_ind,pois_ind[0]).shape[0]\n",
    "                        if pois_intersect > 0:\n",
    "                            all_logs['poisoned_batch_numbers'].append(\n",
    "                                                    (i*epochs + batch,pois_intersect))\n",
    "                        \n",
    "                        p_tst_loss, p_tst_acc = sess.run([tensor_dict['cost'] \n",
    "                                    ,tensor_dict['accuracy']]\n",
    "                                 , feed_dict={tensor_dict['x']: testing_X[pois_ind[1]],\n",
    "                                              tensor_dict['y']: testing_y[pois_ind[1]]})\n",
    "                        #all_logs['poisoned_test_losses'].append(p_tst_loss)\n",
    "                        all_logs['poisoned_test_accuracies'].append(p_tst_acc)\n",
    "                        curr_scope = 'VERIFY'\n",
    "                    \n",
    "                    vars_updated = tf.trainable_variables(scope=curr_scope)\n",
    "                    #dump the weights of model\n",
    "                    net_params = np.array([])\n",
    "                    for gg,param in enumerate(vars_updated):\n",
    "                        net_params = np.append(net_params,param.eval().flatten())\n",
    "                    all_logs['weights'].append(net_params)\n",
    "            # Calculate batch loss and accuracy        \n",
    "            loss, acc = sess.run([tensor_dict['cost'], tensor_dict['accuracy']]\n",
    "                                     , feed_dict={tensor_dict['x']: testing_X,\n",
    "                                                  tensor_dict['y']: testing_y})\n",
    "            print(\"Epoch \" + str(i+1) + \", Loss= \" + \\\n",
    "            \"{:.6f}\".format(loss) + \", Validation Accuracy= \" + \\\n",
    "            \"{:.5f}\".format(acc))\n",
    "            \n",
    "            if poisoned and not pois_ind is None:\n",
    "                p_loss, p_acc = sess.run([tensor_dict['cost'], tensor_dict['accuracy']]\n",
    "                                     , feed_dict={tensor_dict['x']: testing_X[pois_ind[1]]\n",
    "                                                ,tensor_dict['y']: testing_y[pois_ind[1]]})\n",
    "                print(\"*Attack result: Loss= \" + \\\n",
    "                \"{:.6f}\".format(p_loss) + \", Validation Accuracy= \" + \\\n",
    "                \"{:.5f}\".format(p_acc) + '\\n')\n",
    "            \n",
    "            #print(\"Optimization Finished!\")\n",
    "        \n",
    "        #Calculate accuracy for all 10000 mnist test images\n",
    "        test_acc,valid_loss = sess.run([tensor_dict['accuracy'],tensor_dict['cost']], \n",
    "                                        feed_dict={tensor_dict['x']: testing_X,\n",
    "                                                   tensor_dict['y'] : testing_y})\n",
    "        print(\"Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
    "        \n",
    "        if poisoned and not pois_ind is None:\n",
    "            test_acc,valid_loss = sess.run([tensor_dict['accuracy'],tensor_dict['cost']], \n",
    "                                        feed_dict={tensor_dict['x']: testing_X[pois_ind[1]]\n",
    "                                                   ,tensor_dict['y'] : testing_y[pois_ind[1]]})\n",
    "            print(\"Attack Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
    "        \n",
    "    return all_logs\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_graph = create_graph()\n",
    "tensor_dict = create_output_tensors(def_graph,scope='REAL',device=0)\n",
    "tensor_verify_dict = create_output_tensors(def_graph,scope='VERIFY',device=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training poisoned created 9\n",
      "test poisoned created 217\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_train,p_test,p_ind = \\\n",
    "    poison_dataset(train_X,train_y,test_X,test_y,poison_target,\n",
    "                   poison_target_change_to,poison_prob,\n",
    "                   poison_prob_test,show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss= 0.056334, Validation Accuracy= 0.98200\n",
      "Epoch 2, Loss= 0.039635, Validation Accuracy= 0.98750\n",
      "Epoch 3, Loss= 0.037051, Validation Accuracy= 0.98950\n",
      "Epoch 4, Loss= 0.038992, Validation Accuracy= 0.98820\n",
      "Epoch 5, Loss= 0.040028, Validation Accuracy= 0.98770\n",
      "Epoch 6, Loss= 0.047303, Validation Accuracy= 0.98570\n",
      "Epoch 7, Loss= 0.034770, Validation Accuracy= 0.99040\n",
      "Epoch 8, Loss= 0.041883, Validation Accuracy= 0.98730\n",
      "Epoch 9, Loss= 0.061839, Validation Accuracy= 0.98340\n",
      "Epoch 10, Loss= 0.044474, Validation Accuracy= 0.98710\n",
      "Epoch 11, Loss= 0.040087, Validation Accuracy= 0.99020\n",
      "Epoch 12, Loss= 0.041958, Validation Accuracy= 0.98910\n",
      "Epoch 13, Loss= 0.041981, Validation Accuracy= 0.98920\n",
      "Epoch 14, Loss= 0.037748, Validation Accuracy= 0.99090\n",
      "Epoch 15, Loss= 0.030828, Validation Accuracy= 0.99180\n",
      "Epoch 16, Loss= 0.043509, Validation Accuracy= 0.98990\n",
      "Epoch 17, Loss= 0.032568, Validation Accuracy= 0.99260\n",
      "Epoch 18, Loss= 0.037488, Validation Accuracy= 0.99200\n",
      "Epoch 19, Loss= 0.039999, Validation Accuracy= 0.99080\n",
      "Epoch 20, Loss= 0.032774, Validation Accuracy= 0.99340\n",
      "Epoch 21, Loss= 0.037311, Validation Accuracy= 0.99240\n",
      "Epoch 22, Loss= 0.039671, Validation Accuracy= 0.99050\n",
      "Epoch 23, Loss= 0.038580, Validation Accuracy= 0.99110\n",
      "Epoch 24, Loss= 0.038828, Validation Accuracy= 0.99220\n",
      "Epoch 25, Loss= 0.041211, Validation Accuracy= 0.99110\n",
      "Epoch 26, Loss= 0.043313, Validation Accuracy= 0.99050\n",
      "Epoch 27, Loss= 0.038371, Validation Accuracy= 0.99150\n",
      "Epoch 28, Loss= 0.045205, Validation Accuracy= 0.99110\n",
      "Epoch 29, Loss= 0.033537, Validation Accuracy= 0.99120\n",
      "Epoch 30, Loss= 0.040035, Validation Accuracy= 0.99230\n",
      "Testing Accuracy: 0.99230\n"
     ]
    }
   ],
   "source": [
    "clean_logs = run_without_verify(def_graph,tensor_dict,train_X,train_y,test_X,test_y,\n",
    "          epoch_seed=128527,poisoned=False,pois_ind = None,log_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['weights', 'poisoned_batch_numbers', 'bacth_losses', 'batch_accuracies', 'test_losses', 'test_accuracies'])\n",
      "14040\n",
      "468.0\n",
      "(356234,)\n"
     ]
    }
   ],
   "source": [
    "import bz2\n",
    "import pickle\n",
    "print (clean_logs.keys())\n",
    "print (len(clean_logs['weights']))\n",
    "print (len(clean_logs['weights'])/epochs)\n",
    "print (clean_logs['weights'][0].shape)\n",
    "\n",
    "mnist_file = 'madeup_mnist/clean_run/'\n",
    "meta_log = {k: clean_logs[k] for k in ['poisoned_batch_numbers','test_accuracies']}\n",
    "with bz2.BZ2File(mnist_file+'meta.pickle', 'wb') as f:\n",
    "    pickle.dump(meta_log, f,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "batches_per_epoch = len(clean_logs['weights'])//epochs\n",
    "for c in range(epochs):\n",
    "    with bz2.BZ2File(mnist_file+'weights_epoch_'+str(c)+'.pickle.bz2', 'wb') as f:\n",
    "        pickle.dump(clean_logs['weights'][c*(batches_per_epoch):\n",
    "                                          min((c+1)*batches_per_epoch,\n",
    "                                              len(clean_logs['weights']))]\n",
    "                , f,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*- configuration with poison seed 6756 and poison prob 0.1\n",
      "Epoch 1, Loss= 0.071180, Validation Accuracy= 0.97850\n",
      "*Attack result: Loss= 0.112548, Validation Accuracy= 0.98387\n",
      "\n",
      "Epoch 2, Loss= 0.041152, Validation Accuracy= 0.98680\n",
      "*Attack result: Loss= 0.016375, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 3, Loss= 0.035883, Validation Accuracy= 0.98760\n",
      "*Attack result: Loss= 0.002124, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 4, Loss= 0.034752, Validation Accuracy= 0.98910\n",
      "*Attack result: Loss= 0.001050, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 5, Loss= 0.037212, Validation Accuracy= 0.98860\n",
      "*Attack result: Loss= 0.001399, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 6, Loss= 0.034422, Validation Accuracy= 0.98940\n",
      "*Attack result: Loss= 0.002770, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 7, Loss= 0.035718, Validation Accuracy= 0.98930\n",
      "*Attack result: Loss= 0.001132, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 8, Loss= 0.034355, Validation Accuracy= 0.98920\n",
      "*Attack result: Loss= 0.001446, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 9, Loss= 0.054093, Validation Accuracy= 0.98570\n",
      "*Attack result: Loss= 0.004351, Validation Accuracy= 0.99597\n",
      "\n",
      "Epoch 10, Loss= 0.035280, Validation Accuracy= 0.99060\n",
      "*Attack result: Loss= 0.000059, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 11, Loss= 0.032089, Validation Accuracy= 0.99130\n",
      "*Attack result: Loss= 0.000028, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 12, Loss= 0.038727, Validation Accuracy= 0.99010\n",
      "*Attack result: Loss= 0.000060, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 13, Loss= 0.043756, Validation Accuracy= 0.98950\n",
      "*Attack result: Loss= 0.000012, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 14, Loss= 0.034897, Validation Accuracy= 0.99130\n",
      "*Attack result: Loss= 0.003869, Validation Accuracy= 0.99597\n",
      "\n",
      "Epoch 15, Loss= 0.029826, Validation Accuracy= 0.99240\n",
      "*Attack result: Loss= 0.000133, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 16, Loss= 0.034388, Validation Accuracy= 0.99020\n",
      "*Attack result: Loss= 0.000011, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 17, Loss= 0.043267, Validation Accuracy= 0.99000\n",
      "*Attack result: Loss= 0.000658, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 18, Loss= 0.055200, Validation Accuracy= 0.98870\n",
      "*Attack result: Loss= 0.000246, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 19, Loss= 0.044856, Validation Accuracy= 0.99080\n",
      "*Attack result: Loss= 0.000867, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 20, Loss= 0.038773, Validation Accuracy= 0.99320\n",
      "*Attack result: Loss= 0.000015, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 21, Loss= 0.042318, Validation Accuracy= 0.99020\n",
      "*Attack result: Loss= 0.000385, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 22, Loss= 0.043281, Validation Accuracy= 0.99140\n",
      "*Attack result: Loss= 0.000000, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 23, Loss= 0.043047, Validation Accuracy= 0.99180\n",
      "*Attack result: Loss= 0.000002, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 24, Loss= 0.035843, Validation Accuracy= 0.99330\n",
      "*Attack result: Loss= 0.000018, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 25, Loss= 0.034999, Validation Accuracy= 0.99180\n",
      "*Attack result: Loss= 0.000002, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 26, Loss= 0.035955, Validation Accuracy= 0.99180\n",
      "*Attack result: Loss= 0.000000, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 27, Loss= 0.044463, Validation Accuracy= 0.99130\n",
      "*Attack result: Loss= 0.000000, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 28, Loss= 0.040523, Validation Accuracy= 0.99200\n",
      "*Attack result: Loss= 0.000000, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 29, Loss= 0.063282, Validation Accuracy= 0.99080\n",
      "*Attack result: Loss= 0.000004, Validation Accuracy= 1.00000\n",
      "\n",
      "Epoch 30, Loss= 0.036924, Validation Accuracy= 0.99250\n",
      "*Attack result: Loss= 0.000000, Validation Accuracy= 1.00000\n",
      "\n",
      "Testing Accuracy: 0.99250\n",
      "Attack Testing Accuracy: 1.00000\n",
      "*- configuration with poison seed 656587 and poison prob 0.01\n",
      "Epoch 1, Loss= 0.152667, Validation Accuracy= 0.95780\n",
      "*Attack result: Loss= 3.816584, Validation Accuracy= 0.00000\n",
      "\n",
      "Epoch 2, Loss= 0.077426, Validation Accuracy= 0.96670\n",
      "*Attack result: Loss= 1.502994, Validation Accuracy= 0.13115\n",
      "\n",
      "Epoch 3, Loss= 0.044689, Validation Accuracy= 0.98590\n",
      "*Attack result: Loss= 0.262390, Validation Accuracy= 0.94262\n",
      "\n",
      "Epoch 4, Loss= 0.045143, Validation Accuracy= 0.98570\n",
      "*Attack result: Loss= 0.191642, Validation Accuracy= 0.96311\n",
      "\n",
      "Epoch 5, Loss= 0.049111, Validation Accuracy= 0.98560\n",
      "*Attack result: Loss= 0.191255, Validation Accuracy= 0.96721\n",
      "\n",
      "Epoch 6, Loss= 0.059209, Validation Accuracy= 0.98210\n",
      "*Attack result: Loss= 0.366964, Validation Accuracy= 0.87705\n",
      "\n",
      "Epoch 7, Loss= 0.055540, Validation Accuracy= 0.98360\n",
      "*Attack result: Loss= 0.337952, Validation Accuracy= 0.91803\n",
      "\n",
      "Epoch 8, Loss= 0.064186, Validation Accuracy= 0.98140\n",
      "*Attack result: Loss= 0.503137, Validation Accuracy= 0.84426\n",
      "\n",
      "Epoch 9, Loss= 0.037461, Validation Accuracy= 0.98990\n",
      "*Attack result: Loss= 0.163130, Validation Accuracy= 0.98361\n",
      "\n",
      "Epoch 10, Loss= 0.035547, Validation Accuracy= 0.99020\n",
      "*Attack result: Loss= 0.155717, Validation Accuracy= 0.98361\n",
      "\n",
      "Epoch 11, Loss= 0.043636, Validation Accuracy= 0.98890\n",
      "*Attack result: Loss= 0.344728, Validation Accuracy= 0.92623\n",
      "\n",
      "Epoch 12, Loss= 0.046661, Validation Accuracy= 0.98800\n",
      "*Attack result: Loss= 0.237556, Validation Accuracy= 0.96721\n",
      "\n",
      "Epoch 13, Loss= 0.040983, Validation Accuracy= 0.99010\n",
      "*Attack result: Loss= 0.319709, Validation Accuracy= 0.93852\n",
      "\n",
      "Epoch 14, Loss= 0.047235, Validation Accuracy= 0.98840\n",
      "*Attack result: Loss= 0.308194, Validation Accuracy= 0.95492\n",
      "\n",
      "Epoch 15, Loss= 0.043574, Validation Accuracy= 0.98920\n",
      "*Attack result: Loss= 0.188894, Validation Accuracy= 0.98361\n",
      "\n",
      "Epoch 16, Loss= 0.034383, Validation Accuracy= 0.99200\n",
      "*Attack result: Loss= 0.195387, Validation Accuracy= 0.97951\n",
      "\n",
      "Epoch 17, Loss= 0.043949, Validation Accuracy= 0.98920\n",
      "*Attack result: Loss= 0.147908, Validation Accuracy= 0.98770\n",
      "\n",
      "Epoch 18, Loss= 0.035663, Validation Accuracy= 0.99250\n",
      "*Attack result: Loss= 0.168995, Validation Accuracy= 0.98770\n",
      "\n",
      "Epoch 19, Loss= 0.052269, Validation Accuracy= 0.98980\n",
      "*Attack result: Loss= 0.210380, Validation Accuracy= 0.97951\n",
      "\n",
      "Epoch 20, Loss= 0.043246, Validation Accuracy= 0.99080\n",
      "*Attack result: Loss= 0.172138, Validation Accuracy= 0.98361\n",
      "\n",
      "Epoch 21, Loss= 0.040246, Validation Accuracy= 0.99150\n",
      "*Attack result: Loss= 0.184612, Validation Accuracy= 0.97951\n",
      "\n",
      "Epoch 22, Loss= 0.059503, Validation Accuracy= 0.98820\n",
      "*Attack result: Loss= 0.213190, Validation Accuracy= 0.98361\n",
      "\n",
      "Epoch 23, Loss= 0.053876, Validation Accuracy= 0.99070\n",
      "*Attack result: Loss= 0.286218, Validation Accuracy= 0.97541\n",
      "\n",
      "Epoch 24, Loss= 0.039518, Validation Accuracy= 0.99170\n",
      "*Attack result: Loss= 0.231374, Validation Accuracy= 0.98361\n",
      "\n",
      "Epoch 25, Loss= 0.045162, Validation Accuracy= 0.99040\n",
      "*Attack result: Loss= 0.242970, Validation Accuracy= 0.97541\n",
      "\n",
      "Epoch 26, Loss= 0.040799, Validation Accuracy= 0.99250\n",
      "*Attack result: Loss= 0.200577, Validation Accuracy= 0.98770\n",
      "\n",
      "Epoch 27, Loss= 0.057253, Validation Accuracy= 0.98960\n",
      "*Attack result: Loss= 0.245892, Validation Accuracy= 0.98361\n",
      "\n",
      "Epoch 28, Loss= 0.044170, Validation Accuracy= 0.99180\n",
      "*Attack result: Loss= 0.246133, Validation Accuracy= 0.98361\n",
      "\n",
      "Epoch 29, Loss= 0.050221, Validation Accuracy= 0.99080\n",
      "*Attack result: Loss= 0.254356, Validation Accuracy= 0.97541\n",
      "\n",
      "Epoch 30, Loss= 0.040204, Validation Accuracy= 0.99190\n",
      "*Attack result: Loss= 0.212394, Validation Accuracy= 0.98361\n",
      "\n",
      "Testing Accuracy: 0.99190\n",
      "Attack Testing Accuracy: 0.98361\n",
      "*- configuration with poison seed 67524 and poison prob 0.0015\n",
      "Epoch 1, Loss= 0.294285, Validation Accuracy= 0.96060\n",
      "*Attack result: Loss= 10.170546, Validation Accuracy= 0.00000\n",
      "\n",
      "Epoch 2, Loss= 0.272301, Validation Accuracy= 0.96430\n",
      "*Attack result: Loss= 9.819199, Validation Accuracy= 0.00000\n",
      "\n",
      "Epoch 3, Loss= 0.233020, Validation Accuracy= 0.96430\n",
      "*Attack result: Loss= 8.159891, Validation Accuracy= 0.00000\n",
      "\n",
      "Epoch 4, Loss= 0.256139, Validation Accuracy= 0.96430\n",
      "*Attack result: Loss= 9.207840, Validation Accuracy= 0.00000\n",
      "\n",
      "Epoch 5, Loss= 0.279952, Validation Accuracy= 0.96600\n",
      "*Attack result: Loss= 10.319523, Validation Accuracy= 0.00000\n",
      "\n",
      "Epoch 6, Loss= 0.287241, Validation Accuracy= 0.96690\n",
      "*Attack result: Loss= 10.702821, Validation Accuracy= 0.00000\n",
      "\n",
      "Epoch 7, Loss= 0.313060, Validation Accuracy= 0.96340\n",
      "*Attack result: Loss= 11.410604, Validation Accuracy= 0.00000\n",
      "\n",
      "Epoch 8, Loss= 0.329698, Validation Accuracy= 0.96330\n",
      "*Attack result: Loss= 11.992247, Validation Accuracy= 0.00000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss= 0.286483, Validation Accuracy= 0.96570\n",
      "*Attack result: Loss= 10.522015, Validation Accuracy= 0.00000\n",
      "\n",
      "Epoch 10, Loss= 0.276309, Validation Accuracy= 0.96590\n",
      "*Attack result: Loss= 10.154531, Validation Accuracy= 0.00000\n",
      "\n",
      "Epoch 11, Loss= 0.250898, Validation Accuracy= 0.96630\n",
      "*Attack result: Loss= 9.072399, Validation Accuracy= 0.00000\n",
      "\n",
      "Epoch 12, Loss= 0.158745, Validation Accuracy= 0.96590\n",
      "*Attack result: Loss= 5.167352, Validation Accuracy= 0.00000\n",
      "\n",
      "Epoch 13, Loss= 0.093077, Validation Accuracy= 0.97570\n",
      "*Attack result: Loss= 2.442113, Validation Accuracy= 0.36975\n",
      "\n",
      "Epoch 14, Loss= 0.113508, Validation Accuracy= 0.97390\n",
      "*Attack result: Loss= 3.012245, Validation Accuracy= 0.35294\n",
      "\n",
      "Epoch 15, Loss= 0.117668, Validation Accuracy= 0.97610\n",
      "*Attack result: Loss= 3.072920, Validation Accuracy= 0.47899\n",
      "\n",
      "Epoch 16, Loss= 0.090366, Validation Accuracy= 0.98110\n",
      "*Attack result: Loss= 1.332643, Validation Accuracy= 0.75630\n",
      "\n",
      "Epoch 17, Loss= 0.056575, Validation Accuracy= 0.98700\n",
      "*Attack result: Loss= 0.793704, Validation Accuracy= 0.83613\n",
      "\n",
      "Epoch 18, Loss= 0.078750, Validation Accuracy= 0.98470\n",
      "*Attack result: Loss= 2.030177, Validation Accuracy= 0.66807\n",
      "\n",
      "Epoch 19, Loss= 0.052549, Validation Accuracy= 0.98730\n",
      "*Attack result: Loss= 0.593993, Validation Accuracy= 0.84874\n",
      "\n",
      "Epoch 20, Loss= 0.073114, Validation Accuracy= 0.98380\n",
      "*Attack result: Loss= 1.472237, Validation Accuracy= 0.71429\n",
      "\n",
      "Epoch 21, Loss= 0.072885, Validation Accuracy= 0.98340\n",
      "*Attack result: Loss= 0.873292, Validation Accuracy= 0.79832\n",
      "\n",
      "Epoch 22, Loss= 0.070409, Validation Accuracy= 0.98620\n",
      "*Attack result: Loss= 1.468689, Validation Accuracy= 0.73950\n",
      "\n",
      "Epoch 23, Loss= 0.063269, Validation Accuracy= 0.98600\n",
      "*Attack result: Loss= 0.684056, Validation Accuracy= 0.83613\n",
      "\n",
      "Epoch 24, Loss= 0.075564, Validation Accuracy= 0.98610\n",
      "*Attack result: Loss= 1.264116, Validation Accuracy= 0.78151\n",
      "\n",
      "Epoch 25, Loss= 0.059079, Validation Accuracy= 0.98890\n",
      "*Attack result: Loss= 1.034495, Validation Accuracy= 0.80672\n",
      "\n",
      "Epoch 26, Loss= 0.051165, Validation Accuracy= 0.98810\n",
      "*Attack result: Loss= 0.702507, Validation Accuracy= 0.84454\n",
      "\n",
      "Epoch 27, Loss= 0.103594, Validation Accuracy= 0.98360\n",
      "*Attack result: Loss= 2.350346, Validation Accuracy= 0.72269\n",
      "\n",
      "Epoch 28, Loss= 0.054661, Validation Accuracy= 0.98880\n",
      "*Attack result: Loss= 0.584628, Validation Accuracy= 0.86555\n",
      "\n",
      "Epoch 29, Loss= 0.059834, Validation Accuracy= 0.98770\n",
      "*Attack result: Loss= 0.633091, Validation Accuracy= 0.85294\n",
      "\n",
      "Epoch 30, Loss= 0.063300, Validation Accuracy= 0.98790\n",
      "*Attack result: Loss= 0.832447, Validation Accuracy= 0.82353\n",
      "\n",
      "Testing Accuracy: 0.98790\n",
      "Attack Testing Accuracy: 0.82353\n"
     ]
    }
   ],
   "source": [
    "prob_configs = [(0.1,6756),(0.01,656587),(0.0015,67524)]\n",
    "#prob_configs = [(0.01,656587),(0.0015,67524)]\n",
    "for conf in prob_configs:\n",
    "    poison_prob = conf[0]\n",
    "    poison_seed = conf[1]\n",
    "    print('*- configuration with poison seed {} and poison prob {}'.format\n",
    "          (poison_seed,poison_prob))\n",
    "    p_train,p_test,p_ind = \\\n",
    "    poison_dataset(train_X,train_y,test_X,test_y,poison_target,\n",
    "                   poison_target_change_to,poison_prob,\n",
    "                   poison_prob_test,show=False)\n",
    "    poison_logs = run_without_verify(def_graph,tensor_verify_dict,\n",
    "                                     p_train[0],p_train[1],p_test[0],p_test[1],\n",
    "              epoch_seed=128527,poisoned=True,pois_ind = p_ind,log_weights=True)\n",
    "    mnist_file = 'madeup_mnist/poison_run_{}/'.format(poison_prob)\n",
    "    meta_log = {k: poison_logs[k] for k in ['poisoned_batch_numbers',\n",
    "                                           'test_accuracies','poisoned_test_accuracies']}\n",
    "    with bz2.BZ2File(mnist_file+'meta.pickle', 'wb') as f:\n",
    "        pickle.dump(meta_log, f,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    batches_per_epoch = len(poison_logs['weights'])//epochs\n",
    "    for c in range(epochs):\n",
    "        with bz2.BZ2File(mnist_file+'weights_epoch_'+str(c)+'.pickle.bz2', 'wb') as f:\n",
    "            pickle.dump(poison_logs['weights'][c*(batches_per_epoch):\n",
    "                                               min((c+1)*batches_per_epoch,\n",
    "                                                   len(poison_logs['weights']))]\n",
    "                    , f,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    poison_logs = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
